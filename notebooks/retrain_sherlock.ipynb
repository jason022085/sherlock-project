{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features, retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below first downloads the data (roughly 700K samples), then extract features from the raw data values. <br>\n",
    "If you want to skip this step, you can follow the steps below the feature extraction to load the preprocessed data, \n",
    "retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction \n",
    "from sherlock.features.preprocessing import extract_features_chars, extract_features_embed, extract_features_words, extract_features_paras,extract_features_multi_thread\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data\n",
    "You can skip this step if you want to use a preprocessed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412059\n"
     ]
    }
   ],
   "source": [
    "train_samples = pd.read_parquet('../data/data/raw/train_values.parquet')\n",
    "train_labels = pd.read_parquet('../data/data/raw/train_labels.parquet')\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137353\n"
     ]
    }
   ],
   "source": [
    "validation_samples = pd.read_parquet('../data/data/raw/val_values.parquet')\n",
    "validation_labels = pd.read_parquet('../data/data/raw/val_labels.parquet')\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137353\n"
     ]
    }
   ],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')\n",
    "test_labels = pd.read_parquet('../data/data/raw/test_labels.parquet')\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>['Central Missouri', 'unattached', 'unattached...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>[95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>['Katie Crews', 'Christian Hiraldo', 'Alex Est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>['Christian', 'Non-Christian', 'Unreported', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   values\n",
       "20368   ['Central Missouri', 'unattached', 'unattached...\n",
       "664102  [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "366813  ['Katie Crews', 'Christian Hiraldo', 'Alex Est...\n",
       "530567  ['Christian', 'Non-Christian', 'Unreported', '...\n",
       "176253  ['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>jockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type\n",
       "20368   affiliation\n",
       "664102       weight\n",
       "366813       jockey\n",
       "530567     religion\n",
       "176253      company"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "It is important that the string-representations of lists are first converted into lists of strings.\n",
    "The labels should be a list of semantic types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 80000/80000 [01:36<00:00, 825.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 20000/20000 [01:03<00:00, 313.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3 miniutes 38 seconds\n",
    "train_samples_converted, y_train = convert_string_lists_to_lists(train_samples.head(80000), train_labels.head(80000), \"values\", \"type\")\n",
    "val_samples_converted, y_val = convert_string_lists_to_lists(validation_samples.head(10000), validation_labels.head(10000), \"values\", \"type\")\n",
    "test_samples_converted, y_test = convert_string_lists_to_lists(test_samples.head(20000), test_labels.head(20000), \"values\", \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20368     [Central Missouri, unattached, unattached, Kan...\n",
       "664102    [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "366813    [Katie Crews, Christian Hiraldo, Alex Estrada,...\n",
       "530567    [Christian, Non-Christian, Unreported, Jewish,...\n",
       "176253    [AAF-McQuay Canada Inc., AAF-McQuay Canada Inc...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_converted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每個sample都是list of strings\n",
    "type(test_samples_converted.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len smaple:14641819\n",
      "min len smaple:1\n"
     ]
    }
   ],
   "source": [
    "test_samples_len = [len(x) for x in list(test_samples_converted)]\n",
    "print(f\"max len smaple:{np.max(test_samples_len)}\")\n",
    "print(f\"min len smaple:{np.min(test_samples_len)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20368     [Central Missouri, unattached, unattached, Kan...\n",
       "664102    [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_converted[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Sherlock\\lib\\site-packages\\pandas\\core\\strings.py:167: FutureWarning: Possible nested set at position 1\n",
      "  regex = re.compile(pat, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for data column: 100\n",
      "Extracting features for data column: 200\n",
      "Extracting features for data column: 300\n",
      "Extracting features for data column: 400\n",
      "Extracting features for data column: 500\n",
      "Extracting features for data column: 600\n",
      "Extracting features for data column: 700\n",
      "Extracting features for data column: 800\n",
      "Extracting features for data column: 900\n",
      "Extracting features for data column: 1000\n",
      "Extracting features for data column: 1100\n",
      "Extracting features for data column: 1200\n",
      "Extracting features for data column: 1300\n",
      "Extracting features for data column: 1400\n",
      "Extracting features for data column: 1500\n",
      "Extracting features for data column: 1600\n",
      "Extracting features for data column: 1700\n",
      "Extracting features for data column: 1800\n",
      "Extracting features for data column: 1900\n",
      "Extracting features for data column: 2000\n",
      "Extracting features for data column: 2100\n",
      "Extracting features for data column: 2200\n",
      "Extracting features for data column: 2300\n",
      "Extracting features for data column: 2400\n",
      "Extracting features for data column: 2500\n",
      "Extracting features for data column: 2600\n",
      "Extracting features for data column: 2700\n",
      "Extracting features for data column: 2800\n",
      "Extracting features for data column: 2900\n",
      "Extracting features for data column: 3000\n",
      "Extracting features for data column: 3100\n",
      "Extracting features for data column: 3200\n",
      "Extracting features for data column: 3300\n",
      "Extracting features for data column: 3400\n",
      "Extracting features for data column: 3500\n",
      "Extracting features for data column: 3600\n",
      "Extracting features for data column: 3700\n",
      "Extracting features for data column: 3800\n",
      "Extracting features for data column: 3900\n",
      "Extracting features for data column: 4000\n",
      "Extracting features for data column: 4100\n",
      "Extracting features for data column: 4200\n",
      "Extracting features for data column: 4300\n",
      "Extracting features for data column: 4400\n",
      "Extracting features for data column: 4500\n",
      "Extracting features for data column: 4600\n",
      "Extracting features for data column: 4700\n",
      "Extracting features for data column: 4800\n",
      "Extracting features for data column: 4900\n",
      "Extracting features for data column: 5000\n",
      "Extracting features for data column: 5100\n",
      "Extracting features for data column: 5200\n",
      "Extracting features for data column: 5300\n",
      "Extracting features for data column: 5400\n",
      "Extracting features for data column: 5500\n",
      "Extracting features for data column: 5600\n",
      "Extracting features for data column: 5700\n",
      "Extracting features for data column: 5800\n",
      "Extracting features for data column: 5900\n",
      "Extracting features for data column: 6000\n",
      "Extracting features for data column: 6100\n",
      "Extracting features for data column: 6200\n",
      "Extracting features for data column: 6300\n",
      "Extracting features for data column: 6400\n",
      "Extracting features for data column: 6500\n",
      "Extracting features for data column: 6600\n",
      "Extracting features for data column: 6700\n",
      "Extracting features for data column: 6800\n",
      "Extracting features for data column: 6900\n",
      "Extracting features for data column: 7000\n",
      "Extracting features for data column: 7100\n",
      "Extracting features for data column: 7200\n",
      "Extracting features for data column: 7300\n",
      "Extracting features for data column: 7400\n",
      "Extracting features for data column: 7500\n",
      "Extracting features for data column: 7600\n",
      "Extracting features for data column: 7700\n",
      "Extracting features for data column: 7800\n",
      "Extracting features for data column: 7900\n",
      "Extracting features for data column: 8000\n",
      "Extracting features for data column: 8100\n",
      "Extracting features for data column: 8200\n",
      "Extracting features for data column: 8300\n",
      "Extracting features for data column: 8400\n",
      "Extracting features for data column: 8500\n",
      "Extracting features for data column: 8600\n",
      "Extracting features for data column: 8700\n",
      "Extracting features for data column: 8800\n",
      "Extracting features for data column: 8900\n",
      "Extracting features for data column: 9000\n",
      "Extracting features for data column: 9100\n",
      "Extracting features for data column: 9200\n",
      "Extracting features for data column: 9300\n",
      "Extracting features for data column: 9400\n",
      "Extracting features for data column: 9500\n",
      "Extracting features for data column: 9600\n",
      "Extracting features for data column: 9700\n",
      "Extracting features for data column: 9800\n",
      "Extracting features for data column: 9900\n",
      "Extracting features for data column: 10000\n",
      "Extracting features for data column: 10100\n",
      "Extracting features for data column: 10200\n",
      "Extracting features for data column: 10300\n",
      "Extracting features for data column: 10400\n",
      "Extracting features for data column: 10500\n",
      "Extracting features for data column: 10600\n",
      "Extracting features for data column: 10700\n",
      "Extracting features for data column: 10800\n",
      "Extracting features for data column: 10900\n",
      "Extracting features for data column: 11000\n",
      "Extracting features for data column: 11100\n",
      "Extracting features for data column: 11200\n",
      "Extracting features for data column: 11300\n",
      "Extracting features for data column: 11400\n",
      "Extracting features for data column: 11500\n",
      "Extracting features for data column: 11600\n",
      "Extracting features for data column: 11700\n",
      "Extracting features for data column: 11800\n",
      "Extracting features for data column: 11900\n",
      "Extracting features for data column: 12000\n",
      "Extracting features for data column: 12100\n",
      "Extracting features for data column: 12200\n",
      "Extracting features for data column: 12300\n",
      "Extracting features for data column: 12400\n",
      "Extracting features for data column: 12500\n",
      "Extracting features for data column: 12600\n",
      "Extracting features for data column: 12700\n",
      "Extracting features for data column: 12800\n",
      "Extracting features for data column: 12900\n",
      "Extracting features for data column: 13000\n",
      "Extracting features for data column: 13100\n",
      "Extracting features for data column: 13200\n",
      "Extracting features for data column: 13300\n",
      "Extracting features for data column: 13400\n",
      "Extracting features for data column: 13500\n",
      "Extracting features for data column: 13600\n",
      "Extracting features for data column: 13700\n",
      "Extracting features for data column: 13800\n",
      "Extracting features for data column: 13900\n",
      "Extracting features for data column: 14000\n",
      "Extracting features for data column: 14100\n",
      "Extracting features for data column: 14200\n",
      "Extracting features for data column: 14300\n",
      "Extracting features for data column: 14400\n",
      "Extracting features for data column: 14500\n",
      "Extracting features for data column: 14600\n",
      "Extracting features for data column: 14700\n",
      "Extracting features for data column: 14800\n",
      "Extracting features for data column: 14900\n",
      "Extracting features for data column: 15000\n",
      "Extracting features for data column: 15100\n",
      "Extracting features for data column: 15200\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = extract_features(train_samples_converted.head(80000))\n",
    "#X_val = extract_features(val_samples_converted.head(10000))\n",
    "X_test = extract_features(test_samples_converted.head(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#_ = extract_features_chars(test_samples_converted.head(100))\n",
    "\n",
    "#_ = extract_features_words(test_samples_converted.head(100))\n",
    "\n",
    "#_ = extract_features_paras(test_samples_converted.head(100))\n",
    "\n",
    "#_ = extract_features_embed(test_samples_converted.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_test.keys())[:959] # character distribution(960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_test.keys())[960:1161] # word embedding features(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_test.keys())[1161:1188] # global statistic(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X_test.keys())[1188:1588] # paragraph vector(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaN values with feature means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_means = pd.DataFrame(X_train.mean()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "X_val.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "X_test.fillna(train_columns_means.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain sherlock\n",
    "The model can be retrained using the code below. The model is currently restricted to be trained on 78 classes, the code of the model architecture will soon be added for adjusting this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sherlock(X_train, y_train, X_test, y_test, nn_id='retrained_sherlock');\n",
    "print('Trained and saved new model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with a model\n",
    "If you want to use the pretrained Sherlock model `nn_id` set to \"sherlock\".\n",
    "\n",
    "If you want to use another model, you can use the identifier corresponding to that model.\n",
    "\n",
    "**Note**: There is a bug somewhere in the refactored code which affects the model predictions, this should be fixed soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test, nn_id='sherlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Should be fully deterministic too.\n",
    "f1_score(y_test_subset, predicted_labels[:25],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(predicted_labels).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test_subset).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with preprocessed data using Sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires the data to be downloaded from Google Drive (see first step in notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = pd.read_parquet(\"../data/data/processed/X_test.parquet\")\n",
    "y_test_preprocessed = pd.read_parquet(\"../data/data/processed/y_test.parquet\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test_preprocessed, 'sherlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test_preprocessed, predicted_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(predicted_labels).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to prepare our data for Sherlock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
