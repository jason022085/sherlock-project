{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features, retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below first downloads the data (roughly 700K samples), then extract features from the raw data values. <br>\n",
    "If you want to skip this step, you can follow the steps below the feature extraction to load the preprocessed data, \n",
    "retrain Sherlock and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.features.preprocessing import extract_features, convert_string_lists_to_lists, prepare_feature_extraction\n",
    "from sherlock.deploy.train_sherlock import train_sherlock\n",
    "from sherlock.deploy.predict_sherlock import predict_sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "This will download the raw values and preprocessed files, the corresponding labels as well as a few other supporting files:\n",
    "- `download_data()` will download 3.6GB of data into the `data/` directory.\n",
    "- `prepare_feature_extraction()` will download +/- 800 MB of data into the `features/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the raw and preprocessed data into ../data/data.zip.\n",
      "Data was downloaded.\n",
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n"
     ]
    }
   ],
   "source": [
    "helpers.download_data()\n",
    "prepare_feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSLError: HTTPSConnectionPool(host='docs.google.com', port=443): \n",
    "#Max retries exceeded with url: /uc?export=download&id=1kayd5oNRQm8-NCvA8pIrtezbQ-B1_Vmk \n",
    "#(Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1045)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data\n",
    "You can skip this step if you want to use a preprocessed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412059\n"
     ]
    }
   ],
   "source": [
    "train_samples = pd.read_parquet('../data/data/raw/train_values.parquet')\n",
    "train_labels = pd.read_parquet('../data/data/raw/train_labels.parquet')\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137353\n"
     ]
    }
   ],
   "source": [
    "validation_samples = pd.read_parquet('../data/data/raw/val_values.parquet')\n",
    "validation_labels = pd.read_parquet('../data/data/raw/val_labels.parquet')\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137353\n"
     ]
    }
   ],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')\n",
    "test_labels = pd.read_parquet('../data/data/raw/test_labels.parquet')\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>['Central Missouri', 'unattached', 'unattached...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>[95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>['Katie Crews', 'Christian Hiraldo', 'Alex Est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>['Christian', 'Non-Christian', 'Unreported', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   values\n",
       "20368   ['Central Missouri', 'unattached', 'unattached...\n",
       "664102  [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "366813  ['Katie Crews', 'Christian Hiraldo', 'Alex Est...\n",
       "530567  ['Christian', 'Non-Christian', 'Unreported', '...\n",
       "176253  ['AAF-McQuay Canada Inc.', 'AAF-McQuay Canada ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664102</th>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366813</th>\n",
       "      <td>jockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530567</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176253</th>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type\n",
       "20368   affiliation\n",
       "664102       weight\n",
       "366813       jockey\n",
       "530567     religion\n",
       "176253      company"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_samples.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "It is important that the string-representations of lists are first converted into lists of strings.\n",
    "The labels should be a list of semantic types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 137353/137353 [03:39<00:00, 625.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3 miniutes 38 seconds\n",
    "test_samples_converted, y_test = convert_string_lists_to_lists(test_samples, test_labels, \"values\", \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20368     [Central Missouri, unattached, unattached, Kan...\n",
       "664102    [95, 100, 95, 89, 84, 91, 88, 94, 75, 78, 90, ...\n",
       "366813    [Katie Crews, Christian Hiraldo, Alex Estrada,...\n",
       "530567    [Christian, Non-Christian, Unreported, Jewish,...\n",
       "176253    [AAF-McQuay Canada Inc., AAF-McQuay Canada Inc...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_converted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137353"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每個sample都是list of strings\n",
    "type(test_samples_converted.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_len = [len(x) for x in list(test_samples_converted)]\n",
    "print(f\"max len smaple:{np.max(test_samples_len)}\")\n",
    "print(f\"min len smaple:{np.min(test_samples_len)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given that feature extraction can take long, we only take the first 100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_subset = y_test[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affiliation', 'weight', 'jockey', 'religion', 'company', 'grades', 'area', 'component', 'company', 'manufacturer']\n"
     ]
    }
   ],
   "source": [
    "print(y_test_subset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Doc2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00870995, -0.00090878, -0.01173229, ..., -0.01383935,\n",
       "         0.01876198, -0.08971333],\n",
       "       [-0.05415047, -0.02325091, -0.05282537, ...,  0.00680359,\n",
       "        -0.05299571, -0.08228445],\n",
       "       [-0.17294699,  0.08445425, -0.13954757, ..., -0.14642408,\n",
       "         0.01981621,  0.00363814],\n",
       "       ...,\n",
       "       [ 0.159118  , -0.120624  , -0.01007248, ..., -0.03977996,\n",
       "         0.06222615, -0.20168892],\n",
       "       [-0.2347014 ,  0.05774752, -0.06889017, ..., -0.05309976,\n",
       "        -0.13383879, -0.07816506],\n",
       "       [-0.01524658, -0.06477965, -0.00332214, ..., -0.03715399,\n",
       "         0.04627442, -0.10461713]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 2 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Extracting features for data column: 100\n",
      "Extracting features for data column: 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-38c7999f0d04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_samples_converted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#無法下載時，go head to download on website\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#gensim對於model沒有neg_label屬性該如何補救 ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Sherlock\\lib\\site-packages\\sherlock\\features\\preprocessing.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    174\u001b[0m         f = OrderedDict(\n\u001b[0;32m    175\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_bag_of_characters_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_word_embeddings_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_bag_of_words_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Sherlock\\lib\\site-packages\\sherlock\\features\\word_embeddings.py\u001b[0m in \u001b[0;36mextract_word_embeddings_features\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mword_to_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_vectors_f\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Sherlock\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_test = extract_features(test_samples_converted.head(n=1500))\n",
    "#無法下載時，go head to download on website\n",
    "#gensim對於model沒有neg_label屬性該如何補救 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_[0]-agg-any</th>\n",
       "      <th>n_[0]-agg-all</th>\n",
       "      <th>n_[0]-agg-mean</th>\n",
       "      <th>n_[0]-agg-var</th>\n",
       "      <th>n_[0]-agg-min</th>\n",
       "      <th>n_[0]-agg-max</th>\n",
       "      <th>n_[0]-agg-median</th>\n",
       "      <th>n_[0]-agg-sum</th>\n",
       "      <th>n_[0]-agg-kurtosis</th>\n",
       "      <th>n_[0]-agg-skewness</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.000916</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.000586</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.000922</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_[0]-agg-any  n_[0]-agg-all  n_[0]-agg-mean  n_[0]-agg-var  n_[0]-agg-min  \\\n",
       "0          False          False        0.000000       0.000000              0   \n",
       "1           True          False        0.285714       0.204082              0   \n",
       "2          False          False        0.000000       0.000000              0   \n",
       "3          False          False        0.000000       0.000000              0   \n",
       "4          False          False        0.000000       0.000000              0   \n",
       "\n",
       "   n_[0]-agg-max  n_[0]-agg-median  n_[0]-agg-sum  n_[0]-agg-kurtosis  \\\n",
       "0              0               0.0              0                -3.0   \n",
       "1              1               0.0              2                -1.1   \n",
       "2              0               0.0              0                -3.0   \n",
       "3              0               0.0              0                -3.0   \n",
       "4              0               0.0              0                -3.0   \n",
       "\n",
       "   n_[0]-agg-skewness  ...  par_vec_390  par_vec_391  par_vec_392  \\\n",
       "0            0.000000  ...     0.000948    -0.000673     0.001054   \n",
       "1            0.948683  ...    -0.000106     0.001087     0.000957   \n",
       "2            0.000000  ...    -0.000602    -0.000142     0.000751   \n",
       "3            0.000000  ...     0.000452     0.001220     0.000133   \n",
       "4            0.000000  ...    -0.000535     0.000014    -0.000896   \n",
       "\n",
       "   par_vec_393  par_vec_394  par_vec_395  par_vec_396  par_vec_397  \\\n",
       "0    -0.001001     0.000216    -0.000800    -0.000337    -0.000071   \n",
       "1    -0.000543    -0.000262    -0.000594    -0.000299     0.000577   \n",
       "2     0.000775    -0.001135     0.000224     0.001165     0.000051   \n",
       "3    -0.000771    -0.000916    -0.000937    -0.000586     0.000505   \n",
       "4     0.000420    -0.000129    -0.000553    -0.000922    -0.000088   \n",
       "\n",
       "   par_vec_398  par_vec_399  \n",
       "0    -0.001136     0.000982  \n",
       "1     0.000869     0.001150  \n",
       "2    -0.000282    -0.000050  \n",
       "3     0.000032    -0.000184  \n",
       "4    -0.000957     0.000082  \n",
       "\n",
       "[5 rows x 1588 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1588)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaN values with feature means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have no new data, so we full NaN on take testing set.\n",
    "train_columns_means = pd.DataFrame(X_test.mean()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "# X_validation.fillna(train_columns_means.iloc[0], inplace=True)\n",
    "X_test.fillna(train_columns_means.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain sherlock\n",
    "The model can be retrained using the code below. The model is currently restricted to be trained on 78 classes, the code of the model architecture will soon be added for adjusting this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and compiled model, now fitting model on data.\n",
      "Train on 1500 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 1s 926us/sample - loss: 5.0063 - categorical_accuracy: 0.0187 - val_loss: 4.7088 - val_categorical_accuracy: 0.0107\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 4.8220 - categorical_accuracy: 0.0340 - val_loss: 4.6405 - val_categorical_accuracy: 0.0253\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 4.6481 - categorical_accuracy: 0.0440 - val_loss: 4.6003 - val_categorical_accuracy: 0.0280\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 4.4747 - categorical_accuracy: 0.0633 - val_loss: 4.5682 - val_categorical_accuracy: 0.0433\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 4.3795 - categorical_accuracy: 0.0720 - val_loss: 4.5399 - val_categorical_accuracy: 0.0573\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 4.2955 - categorical_accuracy: 0.0940 - val_loss: 4.5128 - val_categorical_accuracy: 0.0827\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 4.2302 - categorical_accuracy: 0.1053 - val_loss: 4.4849 - val_categorical_accuracy: 0.0920\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 4.1523 - categorical_accuracy: 0.1340 - val_loss: 4.4577 - val_categorical_accuracy: 0.1127\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 4.0982 - categorical_accuracy: 0.1500 - val_loss: 4.4289 - val_categorical_accuracy: 0.1327\n",
      "Epoch 10/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 4.0400 - categorical_accuracy: 0.1700 - val_loss: 4.3982 - val_categorical_accuracy: 0.1533\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 3.9877 - categorical_accuracy: 0.1820 - val_loss: 4.3651 - val_categorical_accuracy: 0.1693\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 3.8967 - categorical_accuracy: 0.1947 - val_loss: 4.3287 - val_categorical_accuracy: 0.1820\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 3.8527 - categorical_accuracy: 0.2040 - val_loss: 4.2896 - val_categorical_accuracy: 0.2080\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 1s 398us/sample - loss: 3.7862 - categorical_accuracy: 0.2287 - val_loss: 4.2466 - val_categorical_accuracy: 0.2373\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 1s 406us/sample - loss: 3.7192 - categorical_accuracy: 0.2473 - val_loss: 4.2011 - val_categorical_accuracy: 0.2493\n",
      "Epoch 16/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 3.6604 - categorical_accuracy: 0.2560 - val_loss: 4.1527 - val_categorical_accuracy: 0.2673\n",
      "Epoch 17/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 3.5819 - categorical_accuracy: 0.2833 - val_loss: 4.1008 - val_categorical_accuracy: 0.2827\n",
      "Epoch 18/100\n",
      "1500/1500 [==============================] - 1s 396us/sample - loss: 3.5364 - categorical_accuracy: 0.2893 - val_loss: 4.0448 - val_categorical_accuracy: 0.2947\n",
      "Epoch 19/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 3.4102 - categorical_accuracy: 0.3227 - val_loss: 3.9857 - val_categorical_accuracy: 0.3047\n",
      "Epoch 20/100\n",
      "1500/1500 [==============================] - 1s 414us/sample - loss: 3.3717 - categorical_accuracy: 0.3067 - val_loss: 3.9219 - val_categorical_accuracy: 0.3253\n",
      "Epoch 21/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 3.3204 - categorical_accuracy: 0.3367 - val_loss: 3.8558 - val_categorical_accuracy: 0.3433\n",
      "Epoch 22/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 3.2444 - categorical_accuracy: 0.3533 - val_loss: 3.7866 - val_categorical_accuracy: 0.3620\n",
      "Epoch 23/100\n",
      "1500/1500 [==============================] - 1s 396us/sample - loss: 3.1779 - categorical_accuracy: 0.3593 - val_loss: 3.7160 - val_categorical_accuracy: 0.3733\n",
      "Epoch 24/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 3.1119 - categorical_accuracy: 0.3600 - val_loss: 3.6438 - val_categorical_accuracy: 0.3860\n",
      "Epoch 25/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 3.0627 - categorical_accuracy: 0.4033 - val_loss: 3.5694 - val_categorical_accuracy: 0.4060\n",
      "Epoch 26/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 2.9987 - categorical_accuracy: 0.3987 - val_loss: 3.4925 - val_categorical_accuracy: 0.4200\n",
      "Epoch 27/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.9093 - categorical_accuracy: 0.4100 - val_loss: 3.4137 - val_categorical_accuracy: 0.4313\n",
      "Epoch 28/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 2.8888 - categorical_accuracy: 0.4167 - val_loss: 3.3348 - val_categorical_accuracy: 0.4440\n",
      "Epoch 29/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.8450 - categorical_accuracy: 0.4193 - val_loss: 3.2554 - val_categorical_accuracy: 0.4593\n",
      "Epoch 30/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 2.7559 - categorical_accuracy: 0.4433 - val_loss: 3.1761 - val_categorical_accuracy: 0.4767\n",
      "Epoch 31/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 2.6774 - categorical_accuracy: 0.4733 - val_loss: 3.0974 - val_categorical_accuracy: 0.4900\n",
      "Epoch 32/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.6507 - categorical_accuracy: 0.4667 - val_loss: 3.0169 - val_categorical_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 2.5949 - categorical_accuracy: 0.4767 - val_loss: 2.9385 - val_categorical_accuracy: 0.5073\n",
      "Epoch 34/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 2.5528 - categorical_accuracy: 0.4827 - val_loss: 2.8601 - val_categorical_accuracy: 0.5200\n",
      "Epoch 35/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.4719 - categorical_accuracy: 0.5087 - val_loss: 2.7820 - val_categorical_accuracy: 0.5320\n",
      "Epoch 36/100\n",
      "1500/1500 [==============================] - 1s 398us/sample - loss: 2.4698 - categorical_accuracy: 0.4927 - val_loss: 2.7066 - val_categorical_accuracy: 0.5373\n",
      "Epoch 37/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 2.3768 - categorical_accuracy: 0.5187 - val_loss: 2.6325 - val_categorical_accuracy: 0.5507\n",
      "Epoch 38/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 2.3518 - categorical_accuracy: 0.5193 - val_loss: 2.5603 - val_categorical_accuracy: 0.5613\n",
      "Epoch 39/100\n",
      "1500/1500 [==============================] - 1s 405us/sample - loss: 2.2452 - categorical_accuracy: 0.5460 - val_loss: 2.4886 - val_categorical_accuracy: 0.5693\n",
      "Epoch 40/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 2.2303 - categorical_accuracy: 0.5487 - val_loss: 2.4185 - val_categorical_accuracy: 0.5840\n",
      "Epoch 41/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.1945 - categorical_accuracy: 0.5407 - val_loss: 2.3507 - val_categorical_accuracy: 0.5960\n",
      "Epoch 42/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 2.1407 - categorical_accuracy: 0.5587 - val_loss: 2.2855 - val_categorical_accuracy: 0.6080\n",
      "Epoch 43/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 2.1479 - categorical_accuracy: 0.5660 - val_loss: 2.2194 - val_categorical_accuracy: 0.6253\n",
      "Epoch 44/100\n",
      "1500/1500 [==============================] - 1s 406us/sample - loss: 2.0491 - categorical_accuracy: 0.5840 - val_loss: 2.1575 - val_categorical_accuracy: 0.6360\n",
      "Epoch 45/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 2.0297 - categorical_accuracy: 0.5840 - val_loss: 2.0980 - val_categorical_accuracy: 0.6447\n",
      "Epoch 46/100\n",
      "1500/1500 [==============================] - 1s 405us/sample - loss: 2.0236 - categorical_accuracy: 0.5833 - val_loss: 2.0385 - val_categorical_accuracy: 0.6547\n",
      "Epoch 47/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.9713 - categorical_accuracy: 0.5973 - val_loss: 1.9811 - val_categorical_accuracy: 0.6707\n",
      "Epoch 48/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.9147 - categorical_accuracy: 0.6140 - val_loss: 1.9234 - val_categorical_accuracy: 0.6773\n",
      "Epoch 49/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.8539 - categorical_accuracy: 0.6307 - val_loss: 1.8672 - val_categorical_accuracy: 0.6840\n",
      "Epoch 50/100\n",
      "1500/1500 [==============================] - 1s 408us/sample - loss: 1.8273 - categorical_accuracy: 0.6440 - val_loss: 1.8150 - val_categorical_accuracy: 0.6940\n",
      "Epoch 51/100\n",
      "1500/1500 [==============================] - 1s 398us/sample - loss: 1.7914 - categorical_accuracy: 0.6273 - val_loss: 1.7643 - val_categorical_accuracy: 0.7013\n",
      "Epoch 52/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 1.7557 - categorical_accuracy: 0.6453 - val_loss: 1.7158 - val_categorical_accuracy: 0.7107\n",
      "Epoch 53/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 1.7483 - categorical_accuracy: 0.6447 - val_loss: 1.6703 - val_categorical_accuracy: 0.7173\n",
      "Epoch 54/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 1.7429 - categorical_accuracy: 0.6233 - val_loss: 1.6233 - val_categorical_accuracy: 0.7233\n",
      "Epoch 55/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.6808 - categorical_accuracy: 0.6620 - val_loss: 1.5805 - val_categorical_accuracy: 0.7353\n",
      "Epoch 56/100\n",
      "1500/1500 [==============================] - 1s 397us/sample - loss: 1.6381 - categorical_accuracy: 0.6727 - val_loss: 1.5390 - val_categorical_accuracy: 0.7440\n",
      "Epoch 57/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.6028 - categorical_accuracy: 0.6840 - val_loss: 1.4944 - val_categorical_accuracy: 0.7507\n",
      "Epoch 58/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 1.5647 - categorical_accuracy: 0.6987 - val_loss: 1.4508 - val_categorical_accuracy: 0.7613\n",
      "Epoch 59/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.5309 - categorical_accuracy: 0.6973 - val_loss: 1.4115 - val_categorical_accuracy: 0.7680\n",
      "Epoch 60/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.5353 - categorical_accuracy: 0.7007 - val_loss: 1.3741 - val_categorical_accuracy: 0.7780\n",
      "Epoch 61/100\n",
      "1500/1500 [==============================] - 1s 397us/sample - loss: 1.4899 - categorical_accuracy: 0.7007 - val_loss: 1.3370 - val_categorical_accuracy: 0.7847\n",
      "Epoch 62/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.4610 - categorical_accuracy: 0.7127 - val_loss: 1.3002 - val_categorical_accuracy: 0.7980\n",
      "Epoch 63/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.4481 - categorical_accuracy: 0.7253 - val_loss: 1.2661 - val_categorical_accuracy: 0.8027\n",
      "Epoch 64/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 1.4338 - categorical_accuracy: 0.7193 - val_loss: 1.2335 - val_categorical_accuracy: 0.8107\n",
      "Epoch 65/100\n",
      "1500/1500 [==============================] - 1s 401us/sample - loss: 1.3703 - categorical_accuracy: 0.7420 - val_loss: 1.2014 - val_categorical_accuracy: 0.8173\n",
      "Epoch 66/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 1.3826 - categorical_accuracy: 0.7213 - val_loss: 1.1686 - val_categorical_accuracy: 0.8227\n",
      "Epoch 67/100\n",
      "1500/1500 [==============================] - 1s 407us/sample - loss: 1.3576 - categorical_accuracy: 0.7387 - val_loss: 1.1386 - val_categorical_accuracy: 0.8307\n",
      "Epoch 68/100\n",
      "1500/1500 [==============================] - 1s 407us/sample - loss: 1.3129 - categorical_accuracy: 0.7467 - val_loss: 1.1106 - val_categorical_accuracy: 0.8380\n",
      "Epoch 69/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.3325 - categorical_accuracy: 0.7413 - val_loss: 1.0832 - val_categorical_accuracy: 0.8433\n",
      "Epoch 70/100\n",
      "1500/1500 [==============================] - 1s 417us/sample - loss: 1.2942 - categorical_accuracy: 0.7493 - val_loss: 1.0584 - val_categorical_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "1500/1500 [==============================] - 1s 408us/sample - loss: 1.3000 - categorical_accuracy: 0.7607 - val_loss: 1.0315 - val_categorical_accuracy: 0.8567\n",
      "Epoch 72/100\n",
      "1500/1500 [==============================] - 1s 411us/sample - loss: 1.2344 - categorical_accuracy: 0.7807 - val_loss: 1.0062 - val_categorical_accuracy: 0.8620\n",
      "Epoch 73/100\n",
      "1500/1500 [==============================] - 1s 402us/sample - loss: 1.2424 - categorical_accuracy: 0.7647 - val_loss: 0.9823 - val_categorical_accuracy: 0.8693\n",
      "Epoch 74/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 1.1909 - categorical_accuracy: 0.7780 - val_loss: 0.9584 - val_categorical_accuracy: 0.8727\n",
      "Epoch 75/100\n",
      "1500/1500 [==============================] - 1s 407us/sample - loss: 1.1716 - categorical_accuracy: 0.7887 - val_loss: 0.9377 - val_categorical_accuracy: 0.8793\n",
      "Epoch 76/100\n",
      "1500/1500 [==============================] - 1s 406us/sample - loss: 1.1623 - categorical_accuracy: 0.7887 - val_loss: 0.9168 - val_categorical_accuracy: 0.8807\n",
      "Epoch 77/100\n",
      "1500/1500 [==============================] - 1s 413us/sample - loss: 1.1427 - categorical_accuracy: 0.7880 - val_loss: 0.8956 - val_categorical_accuracy: 0.8900\n",
      "Epoch 78/100\n",
      "1500/1500 [==============================] - 1s 405us/sample - loss: 1.0998 - categorical_accuracy: 0.8040 - val_loss: 0.8776 - val_categorical_accuracy: 0.8907\n",
      "Epoch 79/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 1.1304 - categorical_accuracy: 0.7907 - val_loss: 0.8589 - val_categorical_accuracy: 0.8940\n",
      "Epoch 80/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 1.0793 - categorical_accuracy: 0.8073 - val_loss: 0.8409 - val_categorical_accuracy: 0.8960\n",
      "Epoch 81/100\n",
      "1500/1500 [==============================] - 1s 418us/sample - loss: 1.0851 - categorical_accuracy: 0.8093 - val_loss: 0.8247 - val_categorical_accuracy: 0.9007\n",
      "Epoch 82/100\n",
      "1500/1500 [==============================] - 1s 417us/sample - loss: 1.0643 - categorical_accuracy: 0.8053 - val_loss: 0.8071 - val_categorical_accuracy: 0.9053\n",
      "Epoch 83/100\n",
      "1500/1500 [==============================] - 1s 414us/sample - loss: 1.0511 - categorical_accuracy: 0.8173 - val_loss: 0.7915 - val_categorical_accuracy: 0.9087\n",
      "Epoch 84/100\n",
      "1500/1500 [==============================] - 1s 412us/sample - loss: 1.0452 - categorical_accuracy: 0.8220 - val_loss: 0.7788 - val_categorical_accuracy: 0.9113\n",
      "Epoch 85/100\n",
      "1500/1500 [==============================] - 1s 406us/sample - loss: 1.0289 - categorical_accuracy: 0.8200 - val_loss: 0.7660 - val_categorical_accuracy: 0.9107\n",
      "Epoch 86/100\n",
      "1500/1500 [==============================] - 1s 415us/sample - loss: 1.0048 - categorical_accuracy: 0.8200 - val_loss: 0.7535 - val_categorical_accuracy: 0.9107\n",
      "Epoch 87/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 1.0076 - categorical_accuracy: 0.8320 - val_loss: 0.7402 - val_categorical_accuracy: 0.9140\n",
      "Epoch 88/100\n",
      "1500/1500 [==============================] - 1s 398us/sample - loss: 0.9801 - categorical_accuracy: 0.8333 - val_loss: 0.7271 - val_categorical_accuracy: 0.9133\n",
      "Epoch 89/100\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 0.9599 - categorical_accuracy: 0.8427 - val_loss: 0.7131 - val_categorical_accuracy: 0.9200\n",
      "Epoch 90/100\n",
      "1500/1500 [==============================] - 1s 405us/sample - loss: 0.9555 - categorical_accuracy: 0.8380 - val_loss: 0.7023 - val_categorical_accuracy: 0.9207\n",
      "Epoch 91/100\n",
      "1500/1500 [==============================] - 1s 412us/sample - loss: 0.9460 - categorical_accuracy: 0.8467 - val_loss: 0.6897 - val_categorical_accuracy: 0.9220\n",
      "Epoch 92/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 0.9337 - categorical_accuracy: 0.8473 - val_loss: 0.6773 - val_categorical_accuracy: 0.9280\n",
      "Epoch 93/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 0.9198 - categorical_accuracy: 0.8547 - val_loss: 0.6642 - val_categorical_accuracy: 0.9300\n",
      "Epoch 94/100\n",
      "1500/1500 [==============================] - 1s 408us/sample - loss: 0.8807 - categorical_accuracy: 0.8627 - val_loss: 0.6533 - val_categorical_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "1500/1500 [==============================] - 1s 410us/sample - loss: 0.9048 - categorical_accuracy: 0.8433 - val_loss: 0.6445 - val_categorical_accuracy: 0.9320\n",
      "Epoch 96/100\n",
      "1500/1500 [==============================] - 1s 411us/sample - loss: 0.8667 - categorical_accuracy: 0.8680 - val_loss: 0.6362 - val_categorical_accuracy: 0.9313\n",
      "Epoch 97/100\n",
      "1500/1500 [==============================] - 1s 407us/sample - loss: 0.8753 - categorical_accuracy: 0.8587 - val_loss: 0.6296 - val_categorical_accuracy: 0.9320\n",
      "Epoch 98/100\n",
      "1500/1500 [==============================] - 1s 403us/sample - loss: 0.8790 - categorical_accuracy: 0.8527 - val_loss: 0.6219 - val_categorical_accuracy: 0.9313\n",
      "Epoch 99/100\n",
      "1500/1500 [==============================] - 1s 404us/sample - loss: 0.8620 - categorical_accuracy: 0.8613 - val_loss: 0.6133 - val_categorical_accuracy: 0.9327\n",
      "Epoch 100/100\n",
      "1500/1500 [==============================] - 1s 400us/sample - loss: 0.8429 - categorical_accuracy: 0.8620 - val_loss: 0.6053 - val_categorical_accuracy: 0.9327\n",
      "Retrained Sherlock.\n",
      "Trained and saved new model.\n"
     ]
    }
   ],
   "source": [
    "train_sherlock(X_test, y_test[:1500], X_test, y_test[:1500], nn_id='retrained_sherlock');\n",
    "print('Trained and saved new model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with a model\n",
    "If you want to use the pretrained Sherlock model `nn_id` set to \"sherlock\".\n",
    "\n",
    "If you want to use another model, you can use the identifier corresponding to that model.\n",
    "\n",
    "**Note**: There is a bug somewhere in the refactored code which affects the model predictions, this should be fixed soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test, nn_id='sherlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['team Name', 'depth', 'jockey', ..., 'age', 'status', 'rank'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affiliation',\n",
       " 'weight',\n",
       " 'jockey',\n",
       " 'religion',\n",
       " 'company',\n",
       " 'grades',\n",
       " 'area',\n",
       " 'component',\n",
       " 'company',\n",
       " 'manufacturer',\n",
       " 'weight',\n",
       " 'genre',\n",
       " 'album',\n",
       " 'origin',\n",
       " 'description',\n",
       " 'status',\n",
       " 'credit',\n",
       " 'team Name',\n",
       " 'artist',\n",
       " 'address',\n",
       " 'age',\n",
       " 'album',\n",
       " 'club',\n",
       " 'description',\n",
       " 'family']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\FY110_IFLRP\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\FY110_IFLRP\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5199999999999999"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be fully deterministic too.\n",
    "f1_score(y_test_subset, predicted_labels[:25],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics.classification.f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicted_labels).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test_subset).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions with preprocessed data using Sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires the data to be downloaded from Google Drive (see first step in notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = pd.read_parquet(\"../data/data/processed/X_test.parquet\")\n",
    "y_test_preprocessed = pd.read_parquet(\"../data/data/processed/y_test.parquet\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_entropy</th>\n",
       "      <th>frac_unique</th>\n",
       "      <th>frac_numcells</th>\n",
       "      <th>frac_textcells</th>\n",
       "      <th>avg_num_cells</th>\n",
       "      <th>std_num_cells</th>\n",
       "      <th>avg_text_cells</th>\n",
       "      <th>std_text_cells</th>\n",
       "      <th>avg_spec_cells</th>\n",
       "      <th>std_spec_cells</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.122181</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.290</td>\n",
       "      <td>5.077194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>-0.029472</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.090851</td>\n",
       "      <td>-0.125505</td>\n",
       "      <td>-0.027747</td>\n",
       "      <td>0.028412</td>\n",
       "      <td>-0.078901</td>\n",
       "      <td>0.054292</td>\n",
       "      <td>-0.049115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.817487</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.058</td>\n",
       "      <td>0.233743</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244085</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.079978</td>\n",
       "      <td>-0.014825</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-0.078689</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>-0.112550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.166061</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>11.527</td>\n",
       "      <td>2.688730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>-0.088117</td>\n",
       "      <td>-0.048036</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.109643</td>\n",
       "      <td>-0.070223</td>\n",
       "      <td>-0.009666</td>\n",
       "      <td>-0.081991</td>\n",
       "      <td>-0.041528</td>\n",
       "      <td>-0.094458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.316887</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.053</td>\n",
       "      <td>1.960151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063415</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>-0.033859</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>0.075499</td>\n",
       "      <td>-0.009511</td>\n",
       "      <td>-0.070606</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.955528</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.531804</td>\n",
       "      <td>20.268</td>\n",
       "      <td>9.593132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>-0.213604</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>-0.009626</td>\n",
       "      <td>-0.154028</td>\n",
       "      <td>-0.090470</td>\n",
       "      <td>-0.013950</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>-0.139673</td>\n",
       "      <td>-0.115430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_entropy  frac_unique  frac_numcells  frac_textcells  avg_num_cells  \\\n",
       "0     2.122181        0.005          0.000             1.0          0.000   \n",
       "1     3.817487        0.015          1.000             0.0          2.058   \n",
       "2     3.166061        0.009          0.120             1.0          0.120   \n",
       "3     2.316887        0.005          0.000             1.0          0.000   \n",
       "4     6.955528        0.163          0.018             1.0          0.072   \n",
       "\n",
       "   std_num_cells  avg_text_cells  std_text_cells  avg_spec_cells  \\\n",
       "0       0.000000          12.290        5.077194             0.0   \n",
       "1       0.233743           0.000        0.000000             0.0   \n",
       "2       0.324962          11.527        2.688730             0.0   \n",
       "3       0.000000           9.053        1.960151             0.0   \n",
       "4       0.531804          20.268        9.593132             0.0   \n",
       "\n",
       "   std_spec_cells  ...  par_vec_390  par_vec_391  par_vec_392  par_vec_393  \\\n",
       "0             0.0  ...     0.023563    -0.029472     0.002835     0.090851   \n",
       "1             0.0  ...     0.244085    -0.055574     0.017600     0.079978   \n",
       "2             0.0  ...     0.018266    -0.088117    -0.048036    -0.011286   \n",
       "3             0.0  ...    -0.063415    -0.000197     0.012020    -0.033859   \n",
       "4             0.0  ...     0.015399    -0.213604     0.029100    -0.009626   \n",
       "\n",
       "   par_vec_394  par_vec_395  par_vec_396  par_vec_397  par_vec_398  \\\n",
       "0    -0.125505    -0.027747     0.028412    -0.078901     0.054292   \n",
       "1    -0.014825     0.006086     0.121871    -0.078689    -0.069111   \n",
       "2    -0.109643    -0.070223    -0.009666    -0.081991    -0.041528   \n",
       "3     0.063092     0.075499    -0.009511    -0.070606     0.061907   \n",
       "4    -0.154028    -0.090470    -0.013950     0.036592    -0.139673   \n",
       "\n",
       "   par_vec_399  \n",
       "0    -0.049115  \n",
       "1    -0.112550  \n",
       "2    -0.094458  \n",
       "3     0.065065  \n",
       "4    -0.115430  \n",
       "\n",
       "[5 rows x 1588 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "0  affiliation\n",
       "1       weight\n",
       "2       jockey\n",
       "3     religion\n",
       "4      company"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_sherlock(X_test_preprocessed, 'sherlock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855186356849649"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_preprocessed, predicted_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicted_labels).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to prepare our data for Sherlock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
